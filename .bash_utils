# vim: set syntax=sh


################################### Aliases ####################################

if [[ "$(uname)" != "Darwin" ]]; then
    alias ls='ls --color=auto'
else
    alias ls='ls -G'
fi

alias ll='ls -al'
alias lh='ls -alh'
alias lrt='ls -Alrt'
alias l25='ls -Alrt | tail -25'
alias lsd='ls -ald . */'

alias  grep='grep  --color=auto'
alias fgrep='fgrep --color=auto'
alias egrep='egrep --color=auto'

alias bim='vim'
alias vsafe='vim -u NONE'
alias view='vim -R'



################################## Functions ###################################

# Generates a handful of good password candidates.
pwgen() {
    tr -cd '[:alnum:]_.-' < /dev/urandom \
    | fold -b -w "${LEN:-16}" \
    | grep '[[:lower:]]' | grep '[[:upper:]]' | grep '[[:digit:]]' | grep '[[:punct:]]' \
    | grep '^[[:alpha:]]' \
    | grep '[[:alnum:]]$' \
    | grep -vE '(.)\1' \
    | head -n "${QTY:-5}"
}


div() {
    echo ""
    echo "============================================================"
    echo ""
}


# Change to the root of the current git repo
groot() {
    if git_root=$(git rev-parse --show-toplevel 2>/dev/null); then
        pushd "${git_root}"
    fi
}


# Useful when using tail -f when `ts` isn't available.
addtime() { gawk '{ print strftime("[%H:%M:%S]"), $0; fflush(); }'; }


# List files over 1MB in size, formatted in a way where "| sort -n" is convenient
bigfiles() { find "${1:-.}" -type f -size +1M -printf "%10k kb\t%p\n"; }


# Converts lines into a fixed column width table.
# Each line has $1 columns (default 4)
# Each column is $2 characters wide (default 20)
# Comment lines (starting with #) are skipped
nprint() {
    per_line="${1:-4}"
    col_size="${2:-20}"

    gawk -v per_line="${per_line}" -v col_size="${col_size}" '
    function trim(str) {
        sub(/^[ \t]+/, "", str)
        sub(/[ \t]+$/, "", str)
        return str
    }
    {
        # Skipping comment lines and resetting offset
        if ( $0 ~ /^#/ ) {
            if ( eol != "\n" ) { printf("\n") }
            print trim($0)
            offset = 0
            next
        }

        if ( ++offset % per_line == 0 ) {
            eol = "\n"
        } else {
            eol = ""
        }

        # Print line left-justified to col_size width
        printf("%-*s%s", col_size, trim($f), eol)
    }'
}


# Same as nprint, but splits fields within lines as well.
nprint2() {
    per_line="${1:-4}"
    col_size="${2:-20}"

    gawk -v per_line="${per_line}" -v col_size="${col_size}" '
    function trim(str) {
        sub(/^[ \t]+/, "", str)
        sub(/[ \t]+$/, "", str)
        return str
    }
    {
        # Skipping comment lines and resetting offset
        if ( $0 ~ /^[ \t]*#/ ) {
            if ( eol != "\n" ) { printf("\n") }
            print trim($0)
            offset = 0
            next
        }

        for ( f = 1; f <= NF; f++ ) {
            if ( ++offset % per_line == 0 ) {
                eol = "\n"
            } else {
                eol = ""
            }

            # Print line left-justified to col_size width
            printf("%-*s%s", col_size, trim($f), eol)
        }
    }'
}


# Returns the number of parameters passed, useful for counting wildcard matches
count() { echo "$#"; }


# Returns the total size of the passed file names
fsize() {
	perl -e '
        my @units = ("B", "KB", "MB", "GB", "TB");
        my $sum = 0; my $unit_index = 0;
        for my $file_name (@ARGV) {
            my $file_size = -s $file_name;
            $sum += $file_size;
        }
        while ( $sum >= 1024 ) { $sum /= 1024; $unit_index += 1; }
        printf("%.1f %s\n", $sum, $units[$unit_index]);
    ' -- "$@"
}


easy_cat() {
    for file in "$@"; do
        if [[ ! -f "${file}" ]]; then
            continue
        fi

        mime_type=$(file --brief --mime "${file}")
        case "${mime_type}" in
            *"bzip2"*) bunzip2 -c "${file}" ;;
            *"gzip"*)  gunzip  -c "${file}" ;;
            *"xz"*)    unxz    -c "${file}" ;;
            *"zstd"*)  unzstd -qc "${file}" ;;
            *"7z"*)    7z x   -so "${file}" ;;
            *"zip"*)   unzip   -c "${file}" ;;
            *)         cat        "${file}" ;;
        esac
    done
}


# Returns the frequency of the provided field on each input line
# Works similar to `sort | uniq -c` except faster for low cardinality input
freq() {
    gawk -e '
        {
            seen[$pos] += 1
        }

        END {
            n = asorti(seen, sorted, "@val_num_asc")
            for (i = 1; i <= n; i++) {
                key = sorted[i]
                qty = seen[key]
                print qty "\t" key
            }
        }
    ' "$@"
}


# Reduces multiple `freq` results down to one by summing counts
reduce() {
    gawk -e '
        {
            # Extracting $1, leaving $0 as everything else
            #   https://stackoverflow.com/a/22908787/477563
            count = $1; $1 = ""; sub(FS, "")
            key   = $0
            seen[key] += count
        }

        END {
            n = asorti(seen, sorted, "@val_num_asc")
            for (i = 1; i <= n; i++) {
                key = sorted[i]
                qty = seen[key]
                print qty "\t" key
            }
        }
    ' "$@"
}


set_title() { printf "\033]0;%s\007" "$*"; }
